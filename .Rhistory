summary(mod.fit)
##2a) The estimated curvature is upward.
plot(x = aba$Shell, y = aba$Rings, ylab = "Number of Rings",
xlab = "Shell Weight", main="Abalone Data Poisson Reg vs log(x)")
curve(expr = exp(mod.fitl$coefficients[1]), add = TRUE, lwd = 2, col="red")
summary(mod.fit)
##2a) The estimated curvature is upward.
plot(x = aba$Shell, y = aba$Rings, ylab = "Number of Rings",
xlab = "Shell Weight", main="Abalone Data Poisson Reg vs log(x)")
curve(expr = exp(mod.fitl$coefficients[1]), add = TRUE, lwd = 1, col="red")
summary(mod.fit)
##2a) The estimated curvature is upward.
plot(x = aba$Shell, y = aba$Rings, ylab = "Number of Rings",
xlab = "Shell Weight", main="Abalone Data Poisson Reg vs log(x)")
curve(expr = exp(mod.fitl$coefficients[1] + log(x)*mod.fitl$coefficients[2]), add = TRUE, lwd = 2, col="red")
plot(x = aba$Shell, y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "Shell Weight", main="Abalone Lin Pred from log(x) Reg")
curve(expr = mod.fitl$coefficients[1] + log(x)*mod.fitl$coefficients[2], add = TRUE, lwd = 2, col="red")
#x11(width = 7, height = 6, pointsize = 12)
plot(x = log(aba$Shell), y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "log(Shell Weight)", main="Abalone Lin Pred from log(x) Reg vs log(x)")
curve(expr = mod.fitl$coefficients[1] + x*mod.fitl$coefficients[2], add = TRUE, lwd = 2, col="red")
##2b) Yes it is a good fit, because we have a approximately straight line the second plot and curve has a same direction with points.
summary(mod.fit)
##2a) The estimated curvature is upward.
plot(x = aba$Shell, y = aba$Rings, ylab = "Number of Rings",
xlab = "Shell Weight", main="Abalone Data Poisson Reg vs log(x)")
curve(expr = exp(mod.fit$coefficients[1] + log(x)*mod.fit$coefficients[2]), add = TRUE, lwd = 2, col="red")
plot(x = aba$Shell, y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "Shell Weight", main="Abalone Lin Pred from log(x) Reg")
curve(expr = mod.fit$coefficients[1] + log(x)*mod.fit$coefficients[2], add = TRUE, lwd = 2, col="red")
#x11(width = 7, height = 6, pointsize = 12)
plot(x = log(aba$Shell), y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "log(Shell Weight)", main="Abalone Lin Pred from log(x) Reg vs log(x)")
curve(expr = mod.fit$coefficients[1] + x*mod.fit$coefficients[2], add = TRUE, lwd = 2, col="red")
##2b) Yes it is a good fit, because we have a approximately straight line the second plot and curve has a same direction with points.
summary(mod.fit2)
library(car)
Anova(mod.fit2)
plot(x = aba$Shell, y = aba$Rings, ylab = "Number of Rings",
xlab = "Shell Weight", main="Abalone Data Poisson Reg vs log(x)")
curve(expr = exp(mod.fit2$coefficients[1] + log(x)*mod.fit2$coefficients[2]+log(x)^2 *mod.fit2$coefficients[3]), add = TRUE, lwd = 2, col="red")
plot(x = aba$Shell, y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "Shell Weight", main="Abalone Lin Pred from log(x) Reg")
curve(expr = mod.fit2$coefficients[1] + log(x)*mod.fit2$coefficients[2]+log(x)^2 *mod.fit2$coefficients[3], add = TRUE, lwd = 2, col="red")
#x11(width = 7, height = 6, pointsize = 12)
plot(x = log(aba$Shell), y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "log(Shell Weight)", main="Abalone Lin Pred from log(x) Reg vs log(x)")
curve(expr = mod.fit2$coefficients[1] + x*mod.fit2$coefficients[2]+(x)^2 *mod.fit2$coefficients[3], add = TRUE, lwd = 2, col="red")
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
mod.fit3 <- glm(numvisit~age+inc+age:inc, family=poisson(link="log"), data=doc)
summary(mod.fit3)
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
mod.fit3 <- glm(numvisit~age+inc+age:inc, family=poisson(link="log"), data=doc)
summary(mod.fit3)
#4a) The fitted model is log(numVisits) = 2.548e-01 + 1.834e-02*age + 5.584e-05* income - 1.405e-06 * (age:income) and it decease the odds of number of visits about -1.405e-06 for each influence with income and age while we hold income and age keep same.
#4b) Because Pr() is greater than 0.05 when we setup alpha = 0.05, so it is significant. So we conclude that the influence between income and age is significant effece on number of visit.
library(car)
Anova(mod.fit3)
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
mod.fit3 <- glm(numvisit~age+inc+age:inc, family=poisson(link="log"), data=doc)
summary(mod.fit3)
#4a) The fitted model is log(numVisits) = 2.548e-01 + 1.834e-02*age + 5.584e-05* income - 1.405e-06 * (age:income) and it decease the odds of number of visits about -1.405e-06 for each influence with income and age while we hold income and age keep same.
#4b) Because Pr() is greater than 0.05 when we setup alpha = 0.05, so it is significant. So we conclude that the influence between income and age is significant effece on number of visit.
library(car)
Anova(mod.fit3)
K.means <- cbind(1,c(-2.07,0.41))
K.means
library(mcprofile)
meanpro <- mcprofile(object=mod.fit3, CM=K.means)
summary(mod.fit2)
library(car)
Anova(mod.fit2)
plot(x = aba$Shell, y = aba$Rings, ylab = "Number of Rings",
xlab = "Shell Weight", main="Abalone Data Poisson Reg vs log(x)")
curve(expr = exp(mod.fit2$coefficients[1] + log(x)*mod.fit2$coefficients[2]+log(x)^2 *mod.fit2$coefficients[3]), add = TRUE, lwd = 2, col="red")
plot(x = aba$Shell, y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "Shell Weight", main="Abalone Lin Pred from log(x) Reg")
curve(expr = mod.fit2$coefficients[1] + log(x)*mod.fit2$coefficients[2]+log(x)^2 *mod.fit2$coefficients[3], add = TRUE, lwd = 2, col="red")
#x11(width = 7, height = 6, pointsize = 12)
plot(x = log(aba$Shell), y = log(aba$Rings), ylab = "Linear Predictor [(log(Rings)]",
xlab = "log(Shell Weight)", main="Abalone Lin Pred from log(x) Reg vs log(x)")
curve(expr = mod.fit2$coefficients[1] + x*mod.fit2$coefficients[2]+(x)^2 *mod.fit2$coefficients[3], add = TRUE, lwd = 2, col="red")
K.means2 <- cbind(1,c(0.1, 0.2, 0.3, 0.4),c(0.1, 0.2, 0.3, 0.4)^2)
K.means2
library(mcprofile)
meanpro2 <- mcprofile(object=mod.fit2, CM=K.means2)
exp(confint(meanpro2))
#3a The model is log(Ring) = 1.80 + 2.61 *log(Shell) - 2.02*log^2(shell)
#3b No.
#3c It is not fit well, because it is far away from points and curve.
doc <- read.csv(file  = "DoctorVisits.csv")
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("I", "M", "F"))
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("DN", "F", "B"))
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("DN", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("D", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("D", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
library(car)
Anova(mod.fit1)
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("D", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
library(car)
Anova(mod.fit1)
####1a) The LR test shows that the education level factor is highly significant, meaning that not all education level has the same number of visit doctor.
library(emmeans)
# Specify values for mean linear predictor calculations
emm1 = emmeans(mod.fit1, specs=~Sexf)
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("D", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
library(car)
Anova(mod.fit1)
####1a) The LR test shows that the education level factor is highly significant, meaning that not all education level has the same number of visit doctor.
library(emmeans)
# Specify values for mean linear predictor calculations
emm1 = emmeans(mod.fit1, specs=~educf)
confint(emm1, type="response")
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("D", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
library(car)
Anova(mod.fit1)
####1a) The LR test shows that the education level factor is highly significant, meaning that not all education level has the same number of visit doctor.
library(emmeans)
# Specify values for mean linear predictor calculations
emm1 = emmeans(mod.fit1, specs=~educf)
confint(emm1, type="response")
####1b) It shows for "education beyond high school" holds 2.27 with a 95% LR CI from 2.17 to 2.38. This is considerably below 95% CI for the mean number of visits for "do not finish high school" for [2.65, 2.93] and "Finish high school" for [2.62, 2.84], so clearly "education beyond high school" have a less mean number of visit doctor.
confint(contrast(emm1, method="pairwise"), type = "response")
confint(contrast(emm1, method="revpairwise"), type = "response")
# Can also be done using
#      confint(pairs(emm1), type = "response")
### Without multiplicity adjustment to compare to LR.
confint(contrast(emm1, method="pairwise"), type = "response", adjust="none")
confint(contrast(emm1, method="revpairwise"), type = "response", adjust="none")
doc <- read.csv(file  = "DoctorVisits.csv")
options(width=60)
# Turn Sex into a factor, "Sexf"
class(doc$educ)
doc$educf <- factor(x=doc$educ, labels=c("D", "F", "B"))
mod.fit1 <- glm(numvisit~educf, family=poisson(link="log"), data=doc)
summary(mod.fit1)
library(car)
Anova(mod.fit1)
####1a) The LR test shows that the education level factor is highly significant, meaning that not all education level has the same number of visit doctor.
library(emmeans)
# Specify values for mean linear predictor calculations
emm1 = emmeans(mod.fit1, specs=~educf)
confint(emm1, type="response")
####1b) It shows for "education beyond high school" holds 2.27 with a 95% LR CI from 2.17 to 2.38. This is considerably below 95% CI for the mean number of visits for "do not finish high school" for [2.65, 2.93] and "Finish high school" for [2.62, 2.84], so clearly "education beyond high school" have a less mean number of visit doctor.
confint(contrast(emm1, method="pairwise"), type = "response")
confint(contrast(emm1, method="revpairwise"), type = "response")
# Can also be done using
#      confint(pairs(emm1), type = "response")
### Without multiplicity adjustment to compare to LR.
confint(contrast(emm1, method="pairwise"), type = "response", adjust="none")
confint(contrast(emm1, method="revpairwise"), type = "response", adjust="none")
###1c Clearly see that D:B and F:b is larger than 1. So, "don't finish high school" has 23% more number of visit than "education beyond high school" and "finish high school" has 20% more number of visit doctor than it.
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
mod.fit2 <- glm(numvisit~age+educf+age:educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
# emtrends() function computes separate slopes
(mod.slopes = emtrends(mod.fit2, specs="educf", var="numvisit"))
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
# emtrends() function computes separate slopes
(mod.slopes = emtrends(mod.fit2, specs="educf", var="numvisit"))
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
(mod.slopes = emtrends(mod.fit2, specs=~educf+numvisit, var="log(numvisit)", at=list(numvisit=c(35, 45, 55))))
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
(mod.slopes = emtrends(mod.fit2, specs=~educf+numvisit, var="log(numvisit)", at=list(numvisit=c(35, 45, 55))))
mod.fit2 <- glm(numvisit~age+educf, family=poisson(link="log"), data=doc)
summary(mod.fit2)
#2a) log(numvisit) = 0.433 + 0.0145 *age + 0.0357* EducfF - 0.1430 *educfB
(mod.slopes = emtrends(mod.fit2, specs=~educf+doc$numvisit, var="log(numvisit)", at=list(numvisit=c(35, 45, 55))))
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv(file = "HorseshoeCrabs.csv")
hc = read.csv(file = "HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
hc = read.csv("HorseshoeCrabs.csv")
head(hc)
summary(hc)
###### Convert categorical variables to factors
# Color (1=”light medium”, 2=”medium”, 3=”dark medium”, 4=”dark”)
hc$colfac = factor(hc$Color,
labels=c("light medium", "medium", "dark medium", "dark"))
levels(hc$colfac)
# Spine (1= good, 2=worn, 3=broken)
hc$spfac = factor(hc$Spine,
labels=c("good", "worn", "broken"))
levels(hc$spfac)
library(car)
###### Some models and analyses using numeric variables only
mod0 = glm(Sat ~ 1, family=poisson(link="log"), data=hc)
mod1 = glm(Sat ~ Weight, family=poisson(link="log"), data=hc)
mod2 = glm(Sat ~ Width, family=poisson(link="log"), data=hc)
mod3 = glm(Sat ~ Weight + Width, family=poisson(link="log"), data=hc)
mod4 = glm(Sat ~ Weight * Width, family=poisson(link="log"), data=hc)
summary(mod0)
summary(mod1)
summary(mod2)
summary(mod3)
summary(mod4)
confint(mod1)
confint(mod2)
confint(mod3)
confint(mod4)
exp(confint(mod1))
exp(confint(mod2))
exp(confint(mod3))
exp(confint(mod4))
Anova(mod1)
Anova(mod2)
Anova(mod3)
Anova(mod4)
library(emmeans)
e4 = emmeans(mod4, specs=~Weight + Width,
at=list(Weight=c(2, 2.5, 3), Width=c(23, 26, 29)))
e4
c4.bywid = contrast(e4, method="revpairwise", by="Width")
confint(c4.bywid, type="response", adjust="none")
###### Some models and analyses using categorical variables only
modc1 = glm(Sat ~ colfac + spfac, family=poisson(link="log"), data=hc)
modc2 = glm(Sat ~ colfac + spfac + colfac:spfac , family=poisson(link="log"), data=hc)
summary(modc1)
summary(modc2)
Anova(modc1)
Anova(modc2)
cstable = xtabs( ~colfac + spfac, data=hc)
cstable
summary(cstable)
cs = chisq.test(cstable, correct=FALSE)
cs
cs$expected
cs$stdres
a = HairEyeColor
haireye = margin.table(x=HairEyeColor, margin=c(1,2))
haireye
mod.fit = glm(data=haireye, formula=Freq~Hair + Eye + Hair:Eye, family=poisson(log))
summary(mod.fit)
library(car)
Anova(mod.fit)
library(emmeans)
emm = emmeans(mod.fit, specs=~Hair + Eye)
emm
con1 = contrast(emm, method="pairwise", by="Eye", type="response")
con2 = contrast(emm, interaction="pairwise", type="response")
con3 = contrast(emm, interaction="del.eff", type="response")
confint(con1, adjust="none")
confint(con2, adjust="none")
confint(con3, adjust="none")
coef.mat <- rbind(c(rep(x=0, times=7), -1,0,1, rep(x=0, times=6)))
coef.mat
library(COUNT)
library(COUNT)
data(mdvis)
head(mdvis)
# age = age of woman; loginc = log of income in Deutsche Marks
mod1 = glm(numvisit~age, family=poisson(link="log"), data=mdvis)
mod2 = glm(numvisit~loginc, family=poisson(link="log"), data=mdvis)
mod3 = glm(numvisit~age * loginc, family=poisson(link="log"), data=mdvis)
mod4 = glm(numvisit~age + I(age^2), family=poisson(link="log"), data=mdvis)
summary(mod1)
summary(mod2)
summary(mod3)
summary(mod4)
library(car)
Anova(mod3)
anova(mod1, mod3, test = "LRT")
library(emmeans)
emm = emmeans(mod1, specs=~age, at=list(age=10*c(2:6)))
confint(emm, type="response")
confint(contrast(emm, method="consec"), type="response")
##############################################################
### STAT 475/675 Midterm 2 2022
###  COVID PROBLEM CODE
### Description on separate file
##############################################################
covid = read.csv(file="Covid Data 4 weeks 2022-03-10.csv")
head(covid)
covid$Age = factor(covid$Age, levels=c("18-29", "30-39","40-49","50-59","60-69","70+"))
covid$Vax = factor(covid$Vax, levels=c("None", "Two", "Three"))
covid$Outcome = factor(covid$Outcome, levels=c("None", "ICU", "Death"))
levels(covid$Vax)
levels(covid$Outcome)
levels(covid$Vax) = c("None", "Two", "Three")
levels(covid$Outcome) = c("None", "ICU", "Death")
xtabs(Count~Vax + Outcome + Age, data=covid)
### Model 1:
model1 = glm(Count ~ Age + Vax + Outcome + Age:Vax + Age:Outcome + Vax:Outcome
+ Age:Vax:Outcome, family=poisson(link="log"), data=covid)
summary(model1)
library(car)
Anova(model1)
library(emmeans)
emm1 = emmeans(model1, specs=~Age + Vax + Outcome)
emm1
confint(contrast(emm1, interaction=list("revpairwise"), by="Age"), adjust="none", type="response")
### Model 2:
model2 = glm(Count ~ Age + Vax + Outcome + Age:Vax + Age:Outcome + Vax:Outcome,
family=poisson(link="log"), data=covid)
summary(model2)
Anova(model2)
emm2 = emmeans(model2, specs=~Age + Vax + Outcome)
emm2
confint(contrast(emm2, interaction=list("revpairwise"), by="Age"), adjust="none", type="response")
emm2.VO = emmeans(model2, specs=~Vax + Outcome)
emm2.VO
confint(contrast(emm2.VO, interaction=list("revpairwise")), adjust="none", type="response")
# Comparison of Richard's and my Wordle results
# Number of times guessing correct word in 1,2,3,4,5,6 guesses
#   or failure in 6 turns
tom = c(0, 7, 38, 39, 20, 4, 2)
# Comparison of Richard's and my Wordle results
# Number of times guessing correct word in 1,2,3,4,5,6 guesses
#   or failure in 6 turns
tom = c(0, 7, 38, 39, 20, 4, 2)
richard = c(1, 23, 137, 170, 78, 10, 5)
c(sum(tom), sum(richard))
#################################################################
# Analysis 1
results = array(data=c(tom, richard), dim=c(7,2),
dimnames=list(Guesses=c("1","2","3","4","5","6","Fail"), Player=c("Tom", "Richard")))
PT1 = prop.table(x=results, margin="Guesses")
PT2 = prop.table(x=results, margin="Player")
round(PT1, 2)
round(PT2, 2)
# Pearson (chi-square) test for association between
#  outcome and age group
aa = chisq.test(x=results, correct = FALSE)
aa
aa$expected
aa$residuals
################################################################
# Analysis 2
worddat = data.frame(Player=rep(c("Tom", "Richard"), each=7),
Guesses=rep(c("1","2","3","4","5","6","Fail"), times=2),
G.score=rep(c(1:7), times=2),
Number = c(tom, richard))
worddat
library(emmeans)
mod1 = glm(Number ~ Player + Guesses, family=poisson(link="log"), data=worddat)
summary(mod1)
emm1 = emmeans(mod1, specs=~ Player + Guesses)
emm1
confint(contrast(emm1, interaction=list("consec")), type="response", adjust="none")
mod2 = glm(Number ~ Player + G.score, family=poisson(link="log"), data=worddat)
summary(mod2)
emm2 = emmeans(mod2, specs=~ Player + G.score, at=list(G.score=c(1:7)))
emm2
confint(contrast(emm2, interaction=list("consec")), type="response", adjust="none")
mod3 = glm(Number ~ Player + Guesses + Player*Guesses, family=poisson(link="log"), data=worddat)
summary(mod3)
emm3 = emmeans(mod3, specs=~ Player + Guesses)
emm3
confint(contrast(emm3, interaction=list("consec")), type="response", adjust="none")
mod4 = glm(Number ~ Player + G.score + Player*G.score, family=poisson(link="log"), data=worddat)
summary(mod4)
emm4 = emmeans(mod4, specs=~ Player + G.score, at=list(G.score=c(1:7)))
emm4
confint(contrast(emm4, interaction=list("consec")), type="response", adjust="none")
mod5 = glm(Number ~ Player + Guesses + Player*G.score, family=poisson(link="log"), data=worddat)
summary(mod5)
rg5 = ref_grid(mod5, cov.reduce=G.score~Guesses)
emm5 = emmeans(rg5, specs=~ Player + Guesses)
emm5
confint(contrast(emm5, interaction=list("consec")), type="response", adjust="none")
test1 = anova(mod2, mod1, test="LRT")
test1
test2 = anova(mod2, mod4, test="LRT")
test2
test3 = anova(mod1, mod3, test="LRT")
test3
test4 = anova(mod1, mod5, test="LRT")
test4
test5 = anova(mod5, mod3, test="LRT")
test5
test6 = anova(mod4, mod5, test="LRT")
test6
birthdat = read.csv(file="LowBirthData.csv")
birthdat = read.csv(file="LowBirthData.csv")
head(birthdat)
birthdat$racef = factor(birthdat$race, labels=c("White", "Black", "Other"))
summary(birthdat)
mod1 = glm(low ~ smoke + racef + age + lwt + ptl + ht + ui + ftv,
family=binomial(link="logit"), data=birthdat)
summary(mod1)
library(car)
Anova(mod1)
library(emmeans)
emm1 = emmeans(mod1, specs=~racef)
emm1
con1 = contrast(emm1, method="pairwise")
confint(con1, type="response")
mod1$deviance / mod1$df.residual
1 + 2* sqrt (2/ mod1$df.residual)
1 + 3* sqrt (2/ mod1$df.residual)
pi.hat = predict(mod1, type = "response")
s.res = rstandard(mod1, type = "pearson")
plot(x = pi.hat, y = s.res, xlab = "Estimated Probability", ylab = "Standardized Pearson residuals",
main = "Standardized residuals vs. pi hat")
abline(h = c(3, 2, 0, -2, -3), lty = "dotted", col = "blue")
smooth.stand <- loess(formula = s.res ~ pi.hat)
# Make sure that loess estimates are ordered by "X" for the plots, so that they are displayed properly
order.pihat <- order(pi.hat)
44 %% 11 + ceiling(5.5)
44 %% 11
44 %/% 11 + ceiling(5.5)
2+2
> 2+2
faculty.input = c("ASci", "FASS", "Bus", "CAT", "Educ", "Env", "HSci", "Sci", "Other")
students.input = c(3557, 11516, 3791, 3008, 1425, 1027, 1412, 3824, 32)
faculty.input = c("ASci", "FASS", "Bus", "CAT", "Educ", "Env", "HSci", "Sci", "Other")
students.input = c(3557, 11516, 3791, 3008, 1425, 1027, 1412, 3824, 32)
data.faculty = data.frame(faculty = faculty.input, students = students.input)
head(data.faculty)
pie(x = data.faculty$students, labels = data.faculty$faculty)
pie(x = data.faculty$students, labels = data.faculty$faculty, main="Pie Chart of Student Enrollment by Faculty")
barplot(height = data.faculty$students, names.arg = data.faculty$faculty, main = "Bar Chart of Student Enrollment by Faculty")
barplot(height = data.faculty$students, names.arg = data.faculty$faculty,
main = "Bar Chart of Student Enrollment by Faculty", ylim = c(0,12000))
barplot(height = data.faculty$students, names.arg = data.faculty$faculty,
las = 2, main = "Bar Chart of Student Enrollment by Faculty", ylim=c(0,12000))
data.cfsb = read.csv(file="CFSB.csv", header=TRUE)
setwd("~/")
setwd("/Users/yang/Documents/course/stat452/2023 fall - Owen G. Ward/project 1 &2/project 1")
setwd("C:/Users/11358/OneDrive/桌面/Assignment/STAT452/Project")
#  Generalized additive model on all variables
gam.all <- gam(
data = data,
formula = Y ~ s(X21) + s(X8) + s(X18) + s(X12) + s(X20) + s(X1) + s(X5) + s(X13) + s(X11),
family = gaussian(link = identity)
)
data <- read.csv("training_data.csv")
dim(data)
library(mgcv)
#  Generalized additive model on all variables
gam.all <- gam(
data = data,
formula = Y ~ s(X21) + s(X8) + s(X18) + s(X12) + s(X20) + s(X1) + s(X5) + s(X13) + s(X11),
family = gaussian(link = identity)
)
summary(gam.all)
# Plots of splines in each dimension
#  Dashed lines are 2-SE bounds
par(mfrow = c(3, 2))
plot(gam.all, main = "GAM marginal splines")
test <- read.csv("test_predictors.csv")
pred.gam <- predict(gam.all, newdata = test)
write.table(pred.gam,
"pred.gam.csv", sep = ",", row.names = FALSE, col.names = FALSE)
